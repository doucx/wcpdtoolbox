# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/00_vision.ipynb.

# %% auto 0
__all__ = ['open_img_cv2', 'bgr2xyz', 'open_img_xyz', 'xyz2rgb', 'show_array_rgb_img', 'show_xyz_img', 'img_xyz_pipe', 'PickImg',
           'VideoGet', 'load_video', 'get_pets_dataloaders', 'get_one_test_img']

# %% ../nbs/00_vision.ipynb 3
from .imports import *

# %% ../nbs/00_vision.ipynb 7
def open_img_cv2(path:str)->array: return (cv2.imread(str(path))*1./255).astype(np.float32)

# %% ../nbs/00_vision.ipynb 9
def bgr2xyz(img:np.array)->Tensor:
    img = cv2.cvtColor(img, cv2.COLOR_BGR2XYZ)
    img = torch.from_numpy(img)
    img = torch.unsqueeze(img, 0).permute(0, 3, 1, 2) if img.dim() == 3 else img.permute(0, 3, 1, 2)
    return img

# %% ../nbs/00_vision.ipynb 11
def open_img_xyz(path)->Tensor: return bgr2xyz(open_img_cv2(path))

# %% ../nbs/00_vision.ipynb 17
def xyz2rgb(img:Tensor):
    img = img.permute(0, 2, 3, 1).cpu().detach().numpy()
    imglist = []
    for im in img:
        imglist.append(cv2.cvtColor(im, cv2.COLOR_XYZ2RGB))
    img = np.stack(imglist)
    return img

# %% ../nbs/00_vision.ipynb 22
def show_array_rgb_img(img:np.array):
    img = img * 255
    img = img.astype(np.uint8)
    l = L()
    if len(img.shape) == 3:
        l.append(PILImage.create(img))
    else:
        for i in img:
            l.append(PILImage.create(i))
    return l

# %% ../nbs/00_vision.ipynb 25
def show_xyz_img(img:Tensor):
    img = xyz2rgb(img)
    l = show_array_rgb_img(img)
    return l

# %% ../nbs/00_vision.ipynb 29
def img_xyz_pipe(): return Transform(enc=open_img_xyz, dec=show_xyz_img)

# %% ../nbs/00_vision.ipynb 34
class PickImg(nn.Module):
    def __init__(self, device="cpu", return_grid=False,):
        super().__init__()
        self.device = device
        self.mat_val = torch.tensor([[0, 1, 1, 0, 0.]]).to(device)
        self.to(device)
        self.return_grid = return_grid
        # self.comb_grid = comb_grid

# %% ../nbs/00_vision.ipynb 36
@patch()
def get_grid_mat(self:PickImg, val:Tensor=None):
    if val == None:
        val = self.mat_val
    s0 = torch.stack([torch.cos(val[:, 0])/val[:, 1], -torch.sin(val[:, 0])/val[:, 1], val[:, 3]])
    s1 = torch.stack([torch.sin(val[:, 0])/val[:, 2], torch.cos(val[:, 0])/val[:, 2], val[:, 4]])
    s = torch.stack([s0, s1]).permute(2, 0, 1).reshape(-1, 2, 3)
    return s.to(self.device)

# %% ../nbs/00_vision.ipynb 38
@patch()
def create_grid(self: PickImg, mats: Tensor, pick_size: list):
    pick_size = torch.Size(pick_size)
    return F.affine_grid(mats, pick_size).to(self.device)

# %% ../nbs/00_vision.ipynb 40
@patch()
def create_grid_by_matval(self: PickImg, pick_size, matval: Tensor = None):
    # use mat val to create grid
    mats = self.get_grid_mat(matval)
    return self.create_grid(mats, pick_size).to(self.device)

# %% ../nbs/00_vision.ipynb 42
@patch()
def create_basic_grid(self: PickImg, img: Tensor, pick_size: list= None, permute = False):
    if pick_size is None: pick_size = img.shape 
    mat = self.get_grid_mat().repeat(img.shape[0], 1, 1).to(self.device)
    basic_grid = self.create_grid(mat, pick_size)
    if permute: basic_grid = basic_grid.permute(0,3,1,2)
    return basic_grid.to(self.device)

# %% ../nbs/00_vision.ipynb 44
@patch()
def create_img_with_grid(self:PickImg, img): return torch.hstack((self.create_basic_grid(img, img.size()).permute(0,3,1,2),img))

# %% ../nbs/00_vision.ipynb 46
@patch()
def forward(self:PickImg,
            img:Tensor, # 4d img
            pick_size:list=[32,32], # like [32, 32]
            grid=None, # Size([n,x,y,c])
            matval=None,  # like [[0,0,0,0,0]]
            padding_mode="reflection", # padding_mode
            **kwargs # grid_sample's kwarg
           ) -> Tensor:
    
    if not grid is None:
        pick_size = [grid.shape[0],img.shape[1]] + pick_size
        img = img.expand(grid.shape[0], *img.shape[1:])
        img = F.grid_sample(img, grid, padding_mode=padding_mode, **kwargs).to(self.device)
        return (img, grid) if self.return_grid else img
    
    if not matval is None:
        pick_size = [matval.shape[0],img.shape[1]] + pick_size
        img = img.expand(matval.shape[0], *img.shape[1:])
        matval = tensor(matval).float()
        grid = self.create_grid_by_matval(pick_size, matval)
        img = F.grid_sample(img, grid, padding_mode=padding_mode, **kwargs).to(self.device)
        return (img, grid) if self.return_grid else img
    
    pick_size = [img.shape[0],img.shape[1]] + pick_size
    grid = self.create_basic_grid(img, pick_size)
    img = F.grid_sample(img, grid, padding_mode=padding_mode, **kwargs).to(self.device)
    return (img, grid) if self.return_grid else img

# %% ../nbs/00_vision.ipynb 55
class VideoGet:
    def __init__(self, 
                 src, # 视频路径,可以为本地地址或网络摄像头
                 queue # 队列
                ):
        
        self.stream = cv2.VideoCapture(src)
        self.grabbed, self.frame = self.stream.read()
        self.stopped = False
        self.q = queue
        
        frame = self.frame
        self.q.put(frame)
    
    def start(self):
        self.t = Thread(target=self._get, args=())
        self.t.start()

    def _get(self):
        while not self.stopped:
            if not self.grabbed:
                self.stop()
            else:
                self.grabbed, self.frame = self.stream.read()
                frame = self.frame
                self.q.put(frame)

    def stop(self):
        self.stopped = True

# %% ../nbs/00_vision.ipynb 57
def load_video(src, # 视频路径,可以为本地地址或网络摄像头
               max_frame=None # 队列与拾取的上限
              ):
    t = 0
    q = Queue(max_frame if max_frame != None else 0)
    v = VideoGet(src, q)
    l = [q.get()[None,:]]
    v.start()
    t += 1
    # time.sleep(0.2)
    while True:
        if not((v.stopped) and q.empty() or ((t >= max_frame) if max_frame != None else False)):
            frame = q.get()
            if not frame is None: 
                l.append(frame[None,:])
                t += 1
        else:
            v.stop()
            break
    return np.vstack(tuple(l))

# %% ../nbs/00_vision.ipynb 63
def get_pets_dataloaders(len_items=800, randomseed=42, item_tfms_size=460, batch_tfms_size=460, batch_tfms_min_scale=0.75, **kwarg):
    path = untar_data(URLs.PETS)
    pets = DataBlock(blocks = (ImageBlock, CategoryBlock),
                     get_items=(lambda x:get_image_files(x)[:len_items]), 
                     splitter=RandomSplitter(seed=randomseed),
                     get_y=using_attr(RegexLabeller(r'(.+)_\d+.jpg$'), 'name'),
                     item_tfms=Resize(item_tfms_size),
                     batch_tfms=aug_transforms(size=batch_tfms_size, min_scale=batch_tfms_min_scale))
    dls = pets.dataloaders(path/"images", **kwarg)
    return dls

# %% ../nbs/00_vision.ipynb 66
def get_one_test_img(imgs=None):
    pick_one = lambda l:l[random.randint(0, len(l)-1)]
    if not imgs is None:
        return open_img_xyz(pick_one(imgs))
    else:
        path = untar_data(URLs.PETS)
        imgs = get_image_files(path/'images')
        return open_img_xyz(pick_one(imgs))
